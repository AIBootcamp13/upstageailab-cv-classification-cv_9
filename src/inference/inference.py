#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì´ë¯¸ì§€ ë¶„ë¥˜ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
- í•™ìŠµëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì˜ˆì¸¡
- submission.csv í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ì €ì¥
"""

import os
import torch
import pandas as pd
import numpy as np
from pathlib import Path
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import torchvision.transforms as transforms
import warnings
warnings.filterwarnings('ignore')

# ì»¤ìŠ¤í…€ ëª¨ë“ˆ ì„í¬íŠ¸
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from model.model_architecture import get_model

class TestDataset(Dataset):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í´ë˜ìŠ¤"""
    
    def __init__(self, df, image_dir, transform=None):
        self.df = df
        self.image_dir = image_dir
        self.transform = transform
    
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        # ì´ë¯¸ì§€ íŒŒì¼ëª…
        img_name = self.df.iloc[idx]['ID']
        img_path = os.path.join(self.image_dir, img_name)
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(img_path).convert('RGB')
        
        # ì „ì²˜ë¦¬
        if self.transform:
            image = self.transform(image)
        
        return image

def get_test_transform():
    """í…ŒìŠ¤íŠ¸ìš© ì „ì²˜ë¦¬ ë³€í™˜"""
    return transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

def load_model(model_path, num_classes, device):
    """ëª¨ë¸ ë¡œë“œ"""
    print(f"ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint = torch.load(model_path, map_location=device)
    
    # ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°ì§€
    model_name = 'efficientnet_b0'  # ê¸°ë³¸ê°’
    if 'model_name' in checkpoint:
        model_name = checkpoint['model_name']
        print(f"ê°ì§€ëœ ëª¨ë¸ ì•„í‚¤í…ì²˜: {model_name}")
    elif 'config' in checkpoint and 'model_name' in checkpoint['config']:
        model_name = checkpoint['config']['model_name']
        print(f"ê°ì§€ëœ ëª¨ë¸ ì•„í‚¤í…ì²˜: {model_name}")
    else:
        print(f"ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ê°ì§€í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©: {model_name}")
    
    # ëª¨ë¸ ìƒì„±
    model = get_model(model_name, num_classes, pretrained=False)
    
    # ê°€ì¤‘ì¹˜ ë¡œë“œ
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model = model.to(device)
    model.eval()
    
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    return model

def get_test_loader(test_csv_path, test_img_dir, batch_size=32):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„±"""
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„± ì¤‘...")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    test_df = pd.read_csv(test_csv_path)
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜: {len(test_df)}")
    
    # ì „ì²˜ë¦¬ ë³€í™˜
    test_transform = get_test_transform()
    
    # ë°ì´í„°ì…‹ ìƒì„±
    test_dataset = TestDataset(test_df, test_img_dir, test_transform)
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    
    print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ (ë°°ì¹˜ ìˆ˜: {len(test_loader)})")
    return test_loader, test_df

def predict(model, test_loader, device):
    """ì˜ˆì¸¡ ì‹¤í–‰"""
    print("ì˜ˆì¸¡ ì‹œì‘...")
    
    predictions = []
    
    with torch.no_grad():
        for batch_idx, images in enumerate(test_loader):
            images = images.to(device)
            outputs = model(images)
            preds = outputs.argmax(dim=1).cpu().numpy()
            predictions.extend(preds)
            
            # ì§„í–‰ë¥  ì¶œë ¥
            if (batch_idx + 1) % 10 == 0:
                print(f"ì˜ˆì¸¡ ì§„í–‰ë¥ : {batch_idx + 1}/{len(test_loader)}")
    
    print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ (ì´ {len(predictions)}ê°œ)")
    return predictions

def save_submission(test_df, predictions, submission_path):
    """submission.csv ì €ì¥"""
    print(f"submission.csv ì €ì¥ ì¤‘: {submission_path}")
    
    # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    submission = pd.DataFrame({
        "ID": test_df["ID"],
        "target": predictions
    })
    
    # ì €ì¥
    submission.to_csv(submission_path, index=False)
    
    print(f"âœ… submission.csv ì €ì¥ ì™„ë£Œ")
    
    # ì˜ˆì¸¡ ê²°ê³¼ í†µê³„
    print(f"\n=== ì˜ˆì¸¡ ê²°ê³¼ í†µê³„ ===")
    print(f"ì´ ì˜ˆì¸¡ ìˆ˜: {len(predictions)}")
    print(f"í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ìˆ˜:")
    for class_id, count in enumerate(np.bincount(predictions)):
        print(f"  í´ë˜ìŠ¤ {class_id}: {count}ê°œ")

def run_inference(model_path, test_csv_path, test_img_dir, submission_path, batch_size=32):
    """ì¶”ë¡  ì‹¤í–‰ ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 50)
    print("ì´ë¯¸ì§€ ë¶„ë¥˜ ì¶”ë¡  ì‹œì‘")
    print("=" * 50)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    # í´ë˜ìŠ¤ ìˆ˜ í™•ì¸ (meta.csvì—ì„œ)
    meta_path = "data/meta.csv"
    if os.path.exists(meta_path):
        meta_df = pd.read_csv(meta_path)
        num_classes = len(meta_df)
        print(f"í´ë˜ìŠ¤ ìˆ˜: {num_classes}")
    else:
        num_classes = 17  # ê¸°ë³¸ê°’
        print(f"meta.csvë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í´ë˜ìŠ¤ ìˆ˜ ì‚¬ìš©: {num_classes}")
    
    # 1. ëª¨ë¸ ë¡œë“œ
    model = load_model(model_path, num_classes, device)
    
    # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„±
    test_loader, test_df = get_test_loader(test_csv_path, test_img_dir, batch_size)
    
    # 3. ì˜ˆì¸¡ ì‹¤í–‰
    predictions = predict(model, test_loader, device)
    
    # 4. submission.csv ì €ì¥
    save_submission(test_df, predictions, submission_path)
    
    print("\n" + "=" * 50)
    print("ğŸ‰ ì¶”ë¡  ì™„ë£Œ!")
    print("=" * 50)

if __name__ == "__main__":
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    
    # ì„¤ì •
    model_path = os.path.join(project_root, "models/best_model.pth")
    test_csv_path = os.path.join(project_root, "data/sample_submission.csv")
    test_img_dir = os.path.join(project_root, "data/test")
    submission_path = os.path.join(project_root, "data/submission.csv")
    
    print(f"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
    print(f"ëª¨ë¸ ê²½ë¡œ: {model_path}")
    print(f"í…ŒìŠ¤íŠ¸ CSV: {test_csv_path}")
    print(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {test_img_dir}")
    
    # ì¶”ë¡  ì‹¤í–‰
    run_inference(model_path, test_csv_path, test_img_dir, submission_path) 