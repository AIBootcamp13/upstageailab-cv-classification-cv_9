#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì´ë¯¸ì§€ ë¶„ë¥˜ ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
EDA ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì²´ê³„ì ì¸ í•™ìŠµ ì‹œìŠ¤í…œ
"""

import os
import sys
import argparse
import torch
import pandas as pd
from pathlib import Path

# í˜„ì¬ íŒŒì¼ì˜ ìœ„ì¹˜ (ì˜ˆ: /root/CV/src/train/run_training.py)
current_dir = os.path.dirname(os.path.abspath(__file__))

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ (ì˜ˆ: /root/CV)
project_root = os.path.abspath(os.path.join(current_dir, '..', '..'))

# ë£¨íŠ¸ ê²½ë¡œë¥¼ PYTHONPATHì— ì¶”ê°€
sys.path.append(project_root)

from src.data.EDA import ImageClassificationEDA
from src.data.data_preprocessing import preprocess_data
from src.model.model_architecture import get_model, get_loss_function
from src.train.training_pipeline import Trainer, ModelEvaluator, get_default_config

def run_eda():
    """EDA ì‹¤í–‰"""
    print("=" * 50)
    print("1ë‹¨ê³„: EDA (íƒìƒ‰ì  ë°ì´í„° ë¶„ì„)")
    print("=" * 50)
    
    data_path = "data/train_aug"
    train_csv_path = "data/train_augmented.csv"
    meta_csv_path = "data/meta.csv"
    
    # EDA ì‹¤í–‰
    eda = ImageClassificationEDA(data_path, train_csv_path, meta_csv_path)
    eda.generate_eda_report()
    
    return eda

def run_preprocessing():
    """ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰"""
    print("\n" + "=" * 50)
    print("2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬")
    print("=" * 50)
    
    try:
        train_loader, val_loader = preprocess_data()
        print("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")
        return train_loader, val_loader
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return None, None

def run_training(train_loader, val_loader, config):
    """ëª¨ë¸ í•™ìŠµ ì‹¤í–‰"""
    print("\n" + "=" * 50)
    print("3ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ")
    print("=" * 50)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    # ëª¨ë¸ ìƒì„±
    model = get_model(config['model_name'], config['num_classes'], pretrained=True)
    
    # í•™ìŠµê¸° ìƒì„± ë° í•™ìŠµ ì‹¤í–‰
    trainer = Trainer(model, train_loader, val_loader, device, config)
    best_accuracy = trainer.train()
    
    return trainer, best_accuracy

def run_evaluation(trainer, val_loader, meta_df, device, model_path=None):
    """ëª¨ë¸ í‰ê°€ ì‹¤í–‰"""
    print("\n" + "=" * 50)
    print("4ë‹¨ê³„: ëª¨ë¸ í‰ê°€")
    print("=" * 50)
    
    # í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    class_names = list(meta_df['class_name'])
    
    # ëª¨ë¸ ë¡œë“œ (í‰ê°€ë§Œ ì‹¤í–‰í•˜ëŠ” ê²½ìš°)
    if model_path and os.path.exists(model_path):
        print(f"ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
        checkpoint = torch.load(model_path, map_location=device)
        
        # ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°ì§€
        model_name = 'efficientnet_b0'  # ê¸°ë³¸ê°’
        
        if 'model_name' in checkpoint:
            model_name = checkpoint['model_name']
            print(f"ì²´í¬í¬ì¸íŠ¸ì—ì„œ ê°ì§€ëœ ëª¨ë¸ ì•„í‚¤í…ì²˜: {model_name}")
        elif 'config' in checkpoint and 'model_name' in checkpoint['config']:
            model_name = checkpoint['config']['model_name']
            print(f"ì²´í¬í¬ì¸íŠ¸ ì„¤ì •ì—ì„œ ê°ì§€ëœ ëª¨ë¸ ì•„í‚¤í…ì²˜: {model_name}")
        else:
            print(f"ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ê°ì§€í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©: {model_name}")
            print("ì²´í¬í¬ì¸íŠ¸ì— model_name ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ëª¨ë¸ ì•„í‚¤í…ì²˜ ìƒì„±
        from ..model.model_architecture import get_model
        model = get_model(model_name, len(class_names), pretrained=False)
        
        # ê°€ì¤‘ì¹˜ ë¡œë“œ
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        
        model = model.to(device)
        model.eval()
        
        # í‰ê°€ê¸° ìƒì„± (ë¡œë“œëœ ëª¨ë¸ ì‚¬ìš©)
        evaluator = ModelEvaluator(model, val_loader, device, class_names)
    else:
        # ê¸°ì¡´ trainerì˜ ëª¨ë¸ ì‚¬ìš©
        evaluator = ModelEvaluator(trainer.model, val_loader, device, class_names)
    
    # í‰ê°€ ì‹¤í–‰
    predictions, targets, probabilities = evaluator.evaluate()
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    save_dir = os.path.join(project_root, "results/evaluation")
    report = evaluator.generate_report(predictions, targets, probabilities, save_dir)
    
    print("âœ… ëª¨ë¸ í‰ê°€ ì™„ë£Œ")
    print(f"í‰ê°€ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {save_dir}")
    
    return report

def create_experiment_config(args):
    """ì‹¤í—˜ ì„¤ì • ìƒì„±"""
    config = get_default_config()
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì„¤ì • ì—…ë°ì´íŠ¸
    if args.model:
        config['model_name'] = args.model
    if args.batch_size:
        config['batch_size'] = args.batch_size
    if args.epochs:
        config['epochs'] = args.epochs
    if args.learning_rate:
        config['learning_rate'] = args.learning_rate
    if args.optimizer:
        config['optimizer'] = args.optimizer
    if args.loss_function:
        config['loss_function'] = args.loss_function
    
    # ì‹¤í—˜ë³„ ì €ì¥ ë””ë ‰í† ë¦¬
    experiment_name = f"{config['model_name']}_{config['optimizer']}_{config['loss_function']}"
    config['save_dir'] = os.path.join(project_root, f"models/{experiment_name}")
    
    return config

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ì´ë¯¸ì§€ ë¶„ë¥˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸')
    parser.add_argument('--model', type=str, default='efficientnet_b0',
                       help='ëª¨ë¸ ì´ë¦„ (efficientnet_b0, resnet50, vit_base_patch16_224, custom_cnn)')
    parser.add_argument('--batch-size', type=int, default=32,
                       help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--epochs', type=int, default=50,
                       help='í•™ìŠµ ì—í¬í¬ ìˆ˜')
    parser.add_argument('--learning-rate', type=float, default=1e-3,
                       help='í•™ìŠµë¥ ')
    parser.add_argument('--optimizer', type=str, default='adamw',
                       help='ì˜µí‹°ë§ˆì´ì € (adam, adamw, sgd)')
    parser.add_argument('--loss-function', type=str, default='cross_entropy',
                       help='ì†ì‹¤ í•¨ìˆ˜ (cross_entropy, focal, label_smoothing)')
    parser.add_argument('--skip-eda', action='store_true',
                       help='EDA ë‹¨ê³„ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-preprocessing', action='store_true',
                       help='ì „ì²˜ë¦¬ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-training', action='store_true',
                       help='í•™ìŠµ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-evaluation', action='store_true',
                       help='í‰ê°€ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--evaluation-only', action='store_true',
                       help='í‰ê°€ ë‹¨ê³„ë§Œ ì‹¤í–‰')
    parser.add_argument('--model-path', type=str, default='models/final_model.pth',
                       help='í‰ê°€í•  ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (evaluation-only ëª¨ë“œì—ì„œ ì‚¬ìš©)')
    
    args = parser.parse_args()
    
    print("ğŸš€ ì´ë¯¸ì§€ ë¶„ë¥˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print(f"ì‹¤í—˜ ì„¤ì •: {args}")
    
    # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(os.path.join(project_root, "results"), exist_ok=True)
    os.makedirs(os.path.join(project_root, "models"), exist_ok=True)
    
    # 1ë‹¨ê³„: EDA
    # eda = None
    # if not args.skip_eda:
    #     eda = run_eda()
    
    # 2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬
    train_loader, val_loader = None, None
    if not args.skip_preprocessing:
        train_loader, val_loader = run_preprocessing()
        if train_loader is None:
            print("âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨ë¡œ ì¸í•´ í•™ìŠµì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return    
    
    # 3ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ
    trainer = None
    best_accuracy = 0.0
    if not args.skip_training:
        config = create_experiment_config(args)
        trainer, best_accuracy = run_training(train_loader, val_loader, config)
    
    # 4ë‹¨ê³„: ëª¨ë¸ í‰ê°€
    if not args.skip_evaluation:
        meta_df = pd.read_csv(os.path.join(project_root, "data/meta.csv"))
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        if args.evaluation_only:
            # í‰ê°€ë§Œ ì‹¤í–‰í•˜ëŠ” ê²½ìš°
            if not os.path.exists(args.model_path):
                print(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {args.model_path}")
                return
            
            # ë°ì´í„° ë¡œë” ìƒì„± (í‰ê°€ìš©)
            train_loader, val_loader = run_preprocessing()
            if val_loader is None:
                print("âŒ ë°ì´í„° ë¡œë” ìƒì„± ì‹¤íŒ¨")
                return
            
            report = run_evaluation(None, val_loader, meta_df, device, args.model_path)
        elif trainer is not None:
            # ì „ì²´ íŒŒì´í”„ë¼ì¸ì—ì„œ í‰ê°€
            report = run_evaluation(trainer, val_loader, meta_df, device)
        else:
            print("âŒ í‰ê°€í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
    
    print("\n" + "=" * 50)
    print("ğŸ‰ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print("=" * 50)
    print(f"ìµœê³  ê²€ì¦ ì •í™•ë„: {best_accuracy:.2f}%")
    print("ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜:")
    print("- ëª¨ë¸: models/")
    print("- í‰ê°€ ê²°ê³¼: results/evaluation/")
    print("- í•™ìŠµ ê³¡ì„ : models/*/training_curves.png")

if __name__ == "__main__":
    main() 