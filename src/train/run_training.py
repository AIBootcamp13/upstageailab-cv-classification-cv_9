#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì´ë¯¸ì§€ ë¶„ë¥˜ ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
EDA ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì²´ê³„ì ì¸ í•™ìŠµ ì‹œìŠ¤í…œ
"""

import os
import sys
import argparse
import torch
import pandas as pd
import numpy as np
from pathlib import Path

# ì»¤ìŠ¤í…€ ëª¨ë“ˆ ì„í¬íŠ¸
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.append(project_root)

from src.data.EDA import ImageClassificationEDA
from src.data.data_preprocessing import preprocess_data
from src.model.model_architecture import get_model, get_loss_function
from src.train.training_pipeline import Trainer, ModelEvaluator, get_default_config

def run_eda():
    """EDA ì‹¤í–‰"""
    print("=" * 50)
    print("1ë‹¨ê³„: EDA (íƒìƒ‰ì  ë°ì´í„° ë¶„ì„)")
    print("=" * 50)
    
    data_path = "data/train"
    train_csv_path = "data/train.csv"
    meta_csv_path = "data/meta.csv"
    
    # EDA ì‹¤í–‰
    eda = ImageClassificationEDA(data_path, train_csv_path, meta_csv_path)
    eda.generate_eda_report()
    
    return eda

def run_preprocessing(use_kfold=True, n_splits=5, fold_idx=None):
    """ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰"""
    print("\n" + "=" * 50)
    print("2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬")
    print("=" * 50)
    
    try:
        if use_kfold:
            print(f"Stratified K-Fold ê²€ì¦ ì‚¬ìš© (í´ë“œ ìˆ˜: {n_splits})")
            if fold_idx is not None:
                print(f"íŠ¹ì • í´ë“œ ì‚¬ìš©: Fold {fold_idx + 1}")
            else:
                print("ê¸°ë³¸ í´ë“œ ì‚¬ìš©: Fold 1")
        
        train_loader, val_loader, validator, dataloaders = preprocess_data(
            use_kfold=use_kfold, 
            n_splits=n_splits, 
            fold_idx=fold_idx
        )
        print("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")
        return train_loader, val_loader, validator, dataloaders
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None, None

def run_training(train_loader, val_loader, config):
    """ëª¨ë¸ í•™ìŠµ ì‹¤í–‰"""
    print("\n" + "=" * 50)
    print("3ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ")
    print("=" * 50)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    # ëª¨ë¸ ìƒì„±
    model = get_model(config['model_name'], config['num_classes'], pretrained=True)
    
    # í•™ìŠµê¸° ìƒì„± ë° í•™ìŠµ ì‹¤í–‰
    trainer = Trainer(model, train_loader, val_loader, device, config)
    best_accuracy = trainer.train()
    
    return trainer, best_accuracy

def run_evaluation(trainer, val_loader, meta_df, device, model_path=None):
    """ëª¨ë¸ í‰ê°€ ì‹¤í–‰"""
    print("\n" + "=" * 50)
    print("4ë‹¨ê³„: ëª¨ë¸ í‰ê°€")
    print("=" * 50)
    
    # í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    class_names = list(meta_df['class_name'])
    
    # ëª¨ë¸ ë¡œë“œ (í‰ê°€ë§Œ ì‹¤í–‰í•˜ëŠ” ê²½ìš°)
    if model_path and os.path.exists(model_path):
        print(f"ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
        checkpoint = torch.load(model_path, map_location=device)
        
        # ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°ì§€
        model_name = 'efficientnet_b0'  # ê¸°ë³¸ê°’
        
        if 'model_name' in checkpoint:
            model_name = checkpoint['model_name']
            print(f"ì²´í¬í¬ì¸íŠ¸ì—ì„œ ê°ì§€ëœ ëª¨ë¸ ì•„í‚¤í…ì²˜: {model_name}")
        elif 'config' in checkpoint and 'model_name' in checkpoint['config']:
            model_name = checkpoint['config']['model_name']
            print(f"ì²´í¬í¬ì¸íŠ¸ ì„¤ì •ì—ì„œ ê°ì§€ëœ ëª¨ë¸ ì•„í‚¤í…ì²˜: {model_name}")
        else:
            print(f"ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ê°ì§€í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©: {model_name}")
            print("ì²´í¬í¬ì¸íŠ¸ì— model_name ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ëª¨ë¸ ì•„í‚¤í…ì²˜ ìƒì„±
        from ..model.model_architecture import get_model
        model = get_model(model_name, len(class_names), pretrained=False)
        
        # ê°€ì¤‘ì¹˜ ë¡œë“œ
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        
        model = model.to(device)
        model.eval()
        
        # í‰ê°€ê¸° ìƒì„± (ë¡œë“œëœ ëª¨ë¸ ì‚¬ìš©)
        evaluator = ModelEvaluator(model, val_loader, device, class_names)
    else:
        # ê¸°ì¡´ trainerì˜ ëª¨ë¸ ì‚¬ìš©
        evaluator = ModelEvaluator(trainer.model, val_loader, device, class_names)
    
    # í‰ê°€ ì‹¤í–‰
    predictions, targets, probabilities = evaluator.evaluate()
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    save_dir = Path("results/evaluation")
    report = evaluator.generate_report(predictions, targets, probabilities, save_dir)
    
    print("âœ… ëª¨ë¸ í‰ê°€ ì™„ë£Œ")
    print(f"í‰ê°€ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {save_dir}")
    
    return report

def create_experiment_config(args):
    """ì‹¤í—˜ ì„¤ì • ìƒì„±"""
    config = get_default_config()
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì„¤ì • ì—…ë°ì´íŠ¸
    if args.model:
        config['model_name'] = args.model
    if args.batch_size:
        config['batch_size'] = args.batch_size
    if args.epochs:
        config['epochs'] = args.epochs
    if args.learning_rate:
        config['learning_rate'] = args.learning_rate
    if args.optimizer:
        config['optimizer'] = args.optimizer
    if args.loss_function:
        config['loss_function'] = args.loss_function
    
    # ì‹¤í—˜ë³„ ì €ì¥ ë””ë ‰í† ë¦¬
    experiment_name = f"{config['model_name']}_{config['optimizer']}_{config['loss_function']}"
    config['save_dir'] = f"models/{experiment_name}"
    
    # wandb ì„¤ì •
    config['use_wandb'] = args.use_wandb
    config['wandb_project'] = args.wandb_project
    config['wandb_run_name'] = args.wandb_run_name
    
    return config

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ì´ë¯¸ì§€ ë¶„ë¥˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸')
    parser.add_argument('--model', type=str, default='efficientnet_b0',
                       help='ëª¨ë¸ ì´ë¦„ (efficientnet_b0, resnet50, vit_base_patch16_224, custom_cnn)')
    parser.add_argument('--batch-size', type=int, default=32,
                       help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--epochs', type=int, default=50,
                       help='í•™ìŠµ ì—í¬í¬ ìˆ˜')
    parser.add_argument('--learning-rate', type=float, default=1e-3,
                       help='í•™ìŠµë¥ ')
    parser.add_argument('--optimizer', type=str, default='adamw',
                       help='ì˜µí‹°ë§ˆì´ì € (adam, adamw, sgd)')
    parser.add_argument('--loss-function', type=str, default='cross_entropy',
                       help='ì†ì‹¤ í•¨ìˆ˜ (cross_entropy, focal, label_smoothing)')
    parser.add_argument('--skip-eda', action='store_true',
                       help='EDA ë‹¨ê³„ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-preprocessing', action='store_true',
                       help='ì „ì²˜ë¦¬ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-training', action='store_true',
                       help='í•™ìŠµ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip-evaluation', action='store_true',
                       help='í‰ê°€ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--evaluation-only', action='store_true',
                       help='í‰ê°€ ë‹¨ê³„ë§Œ ì‹¤í–‰')
    parser.add_argument('--model-path', type=str, default='models/final_model.pth',
                       help='í‰ê°€í•  ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (evaluation-only ëª¨ë“œì—ì„œ ì‚¬ìš©)')
    parser.add_argument('--use-wandb', action='store_true',
                       help='wandb ë¡œê¹… í™œì„±í™”')
    parser.add_argument('--wandb-project', type=str, default='image-classification',
                       help='wandb í”„ë¡œì íŠ¸ ì´ë¦„')
    parser.add_argument('--wandb-run-name', type=str, default=None,
                       help='wandb ì‹¤í–‰ ì´ë¦„ (Noneì´ë©´ ìë™ ìƒì„±)')
    parser.add_argument('--use-kfold', action='store_true', default=True,
                       help='Stratified K-Fold ê²€ì¦ ì‚¬ìš©')
    parser.add_argument('--n-splits', type=int, default=5,
                       help='K-Fold ë¶„í•  ìˆ˜')
    parser.add_argument('--fold-idx', type=int, default=None,
                       help='ì‚¬ìš©í•  í´ë“œ ì¸ë±ìŠ¤ (Noneì´ë©´ ì²« ë²ˆì§¸ í´ë“œ)')
    parser.add_argument('--cross-validate', action='store_true',
                       help='ëª¨ë“  í´ë“œì— ëŒ€í•´ êµì°¨ ê²€ì¦ ì‹¤í–‰')

    
    args = parser.parse_args()
    
    print("ğŸš€ ì´ë¯¸ì§€ ë¶„ë¥˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print(f"ì‹¤í—˜ ì„¤ì •: {args}")
    
    # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs("results", exist_ok=True)
    os.makedirs("models", exist_ok=True)
    
    # 1ë‹¨ê³„: EDA
    # eda = None
    # if not args.skip_eda:
    #     eda = run_eda()
    
    # 2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬
    train_loader, val_loader = None, None
    validator, dataloaders = None, None
    
    if not args.skip_preprocessing:
        train_loader, val_loader, validator, dataloaders = run_preprocessing(
            use_kfold=args.use_kfold,
            n_splits=args.n_splits,
            fold_idx=args.fold_idx
        )
        if train_loader is None:
            print("âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨ë¡œ ì¸í•´ í•™ìŠµì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
    
    # 3ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ
    trainer = None
    best_accuracy = 0.0
    
    if not args.skip_training:
        config = create_experiment_config(args)
        
        if args.cross_validate and validator is not None:
            # ëª¨ë“  í´ë“œì— ëŒ€í•´ êµì°¨ ê²€ì¦
            print("\n" + "=" * 50)
            print("êµì°¨ ê²€ì¦ ì‹œì‘")
            print("=" * 50)
            
            fold_accuracies = []
            fold_trainers = []
            
            for fold_idx in range(len(dataloaders)):
                print(f"\n--- Fold {fold_idx + 1} í•™ìŠµ ì‹œì‘ ---")
                
                # í•´ë‹¹ í´ë“œì˜ ë°ì´í„° ë¡œë” ê°€ì ¸ì˜¤ê¸°
                fold_data = dataloaders[fold_idx]
                fold_train_loader = fold_data['train_loader']
                fold_val_loader = fold_data['val_loader']
                
                # í´ë“œë³„ ì„¤ì • ì—…ë°ì´íŠ¸
                fold_config = config.copy()
                fold_config['save_dir'] = f"{config['save_dir']}/fold_{fold_idx + 1}"
                fold_config['wandb_run_name'] = f"{config['wandb_run_name']}_fold_{fold_idx + 1}" if config['wandb_run_name'] else f"fold_{fold_idx + 1}"
                
                # í•™ìŠµ ì‹¤í–‰
                fold_trainer, fold_accuracy = run_training(fold_train_loader, fold_val_loader, fold_config)
                
                fold_accuracies.append(fold_accuracy)
                fold_trainers.append(fold_trainer)
                
                print(f"Fold {fold_idx + 1} ì •í™•ë„: {fold_accuracy:.4f}")
            
            # êµì°¨ ê²€ì¦ ê²°ê³¼ ìš”ì•½
            mean_accuracy = np.mean(fold_accuracies)
            std_accuracy = np.std(fold_accuracies)
            
            print(f"\n=== êµì°¨ ê²€ì¦ ê²°ê³¼ ===")
            print(f"í‰ê·  ì •í™•ë„: {mean_accuracy:.4f} Â± {std_accuracy:.4f}")
            print(f"ìµœê³  ì •í™•ë„: {max(fold_accuracies):.4f}")
            print(f"ìµœì € ì •í™•ë„: {min(fold_accuracies):.4f}")
            
            # ê²°ê³¼ ì €ì¥
            results = {
                'fold_accuracies': fold_accuracies,
                'mean_accuracy': mean_accuracy,
                'std_accuracy': std_accuracy,
                'best_accuracy': max(fold_accuracies),
                'worst_accuracy': min(fold_accuracies)
            }
            
            import json
            with open(f"{config['save_dir']}/cross_validation_results.json", 'w') as f:
                json.dump(results, f, indent=2)
            
            print(f"êµì°¨ ê²€ì¦ ê²°ê³¼ ì €ì¥: {config['save_dir']}/cross_validation_results.json")
            
            # ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì˜ ëª¨ë¸ì„ ë©”ì¸ ëª¨ë¸ë¡œ ì„¤ì •
            best_fold_idx = np.argmax(fold_accuracies)
            trainer = fold_trainers[best_fold_idx]
            best_accuracy = fold_accuracies[best_fold_idx]
            
            print(f"ìµœê³  ì„±ëŠ¥ ëª¨ë¸: Fold {best_fold_idx + 1} (ì •í™•ë„: {best_accuracy:.4f})")
            
        else:
            # ë‹¨ì¼ í´ë“œ í•™ìŠµ
            trainer, best_accuracy = run_training(train_loader, val_loader, config)
    
    # 4ë‹¨ê³„: ëª¨ë¸ í‰ê°€
    if not args.skip_evaluation:
        meta_df = pd.read_csv("data/meta.csv")
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        if args.evaluation_only:
            # í‰ê°€ë§Œ ì‹¤í–‰í•˜ëŠ” ê²½ìš°
            if not os.path.exists(args.model_path):
                print(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {args.model_path}")
                return
            
            # ë°ì´í„° ë¡œë” ìƒì„± (í‰ê°€ìš©)
            train_loader, val_loader = run_preprocessing()
            if val_loader is None:
                print("âŒ ë°ì´í„° ë¡œë” ìƒì„± ì‹¤íŒ¨")
                return
            
            report = run_evaluation(None, val_loader, meta_df, device, args.model_path)
        elif trainer is not None:
            # ì „ì²´ íŒŒì´í”„ë¼ì¸ì—ì„œ í‰ê°€
            report = run_evaluation(trainer, val_loader, meta_df, device)
        else:
            print("âŒ í‰ê°€í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
    
    print("\n" + "=" * 50)
    print("ğŸ‰ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print("=" * 50)
    print(f"ìµœê³  ê²€ì¦ ì •í™•ë„: {best_accuracy:.2f}%")
    print("ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜:")
    print("- ëª¨ë¸: models/")
    print("- í‰ê°€ ê²°ê³¼: results/evaluation/")
    print("- í•™ìŠµ ê³¡ì„ : models/*/training_curves.png")

if __name__ == "__main__":
    main() 